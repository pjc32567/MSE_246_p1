df.valid$prob <- predict(model_forward,newdata = df.valid, type = "response")
df.train$prob <- predict(model_forward, type = "response")
pred.train <- prediction(df.train$prob, df.train$voted_obama==1)
pred.valid <- prediction(df.valid$prob, df.valid$voted_obama==1)
auc <- performance(pred.train, "auc")
df_int_result[j,2] <- unlist(slot(auc, "y.values"))
auc <- performance(pred.valid, "auc")
df_int_result[j,3] <- unlist(slot(auc, "y.values"))
}
}
maxAUC = max(df_int_result$Valid_AUC)
df_result[i,] = df_int_result[df_int_result$Valid_AUC==maxAUC,1:3]
removeCoef <- df_int_result[df_int_result$Valid_AUC==maxAUC,4]
df_coef <- df_coef[!df_coef %in% removeCoef]
df_int_result <- data.frame(Formula=character(),Train_AUC=numeric(),Valid_AUC=numeric(),coef = character())
df_int_result$Formula <- as.character(df_int_result$Formula)
df_int_result$Train_AUC <- as.numeric(df_int_result$Train_AUC)
df_int_result$Valid_AUC <- as.numeric(df_int_result$Valid_AUC)
df_int_result$coef <- as.character(df_int_result$coef)
}
df_result
df_coef
plot(df_result[,2])
plot(df_result[,3])
library(ggplot2)
ggplot()+geom_abline(mapping = aes(y = df_result[,2]))
ggplot()+geom_smooth(mapping = aes(y = df_result[,2]))
ggplot()+geom_point(mapping = aes(y = df_result[,2]))
ggplot()+geom_point(mapping = aes(x = 1:8, y = df_result[,2]))
ggplot()+geom_smooth(mapping = aes(x = 1:8, y = df_result[,2]))+geom_smooth(mapping = aes(x = 1:8, y = df_result[,3]))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2]))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],colors = "BLUE"))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2]))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = "BLUE"))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2]))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = ""))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2]))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2],color = "Training AUC"))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = "Validation AUC"))
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2],color = "Training AUC"))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = "Validation AUC"))+
xlab("No. of features")+ylab("AUC")
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2],Error = "Training AUC"))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],Error = "Validation AUC"))+
xlab("No. of features")+ylab("AUC")
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2],color = "Training AUC"))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = "Validation AUC"))+
xlab("No. of features")+ylab("AUC")
df_result
df.train <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df.test <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
df.train$voted_obama <- ifelse(df.train$vote_2008 == 'barack obama',1,0)
df.test$voted_obama <- ifelse(df.test$vote_2008 == 'barack obama',1,0)
df.train <- df.train[,-c(8)]
df.test <- df.test[,-c(8)]
model_final <- glm(voted_obama ~ party + ideology + race + sex,
data = df.train,family = "binomial")
df.test$prob <- predict(model_final,newdata = df.test,type = response)
pred.test <- prediction(df.test$prob, df.test$voted_obama==1)
auc <- performance(pred.test, "auc")
auc <- unlist(slot(auc, "y.values"))
df.train <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df.test <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
df.train$voted_obama <- ifelse(df.train$vote_2008 == 'barack obama',1,0)
df.test$voted_obama <- ifelse(df.test$vote_2008 == 'barack obama',1,0)
df.train <- df.train[,-c(8)]
df.test <- df.test[,-c(8)]
model_final <- glm(voted_obama ~ party + ideology + race + sex,
data = df.train,family = "binomial")
df.test$prob <- predict(model_final,newdata = df.test,type = "response")
pred.test <- prediction(df.test$prob, df.test$voted_obama==1)
auc <- performance(pred.test, "auc")
auc <- unlist(slot(auc, "y.values"))
auc
auc_Q2 <- performance(pred.test, "auc")
auc_Q2 <- unlist(slot(auc_Q2, "y.values"))
set.seed(12)
library(caret)
library(ROCR)
df.train <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df.test <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
summary(df.train)
df.train$voted_obama <- ifelse(df.train$vote_2008 == 'barack obama',1,0)
df.test$voted_obama <- ifelse(df.test$vote_2008 == 'barack obama',1,0)
# 1a
model_all_fts <- glm(voted_obama~state+sex+race+age+
education+party+ideology+state_contestedness,
data = df.train,
family = "binomial")
summary(model_all_fts)
df.train$prob <- predict(model_all_fts,type = "response")
df.train$pred <- 0
df.train$pred[df.train$prob >= 0.5] <- 1
df.table <- table(df.train$pred,df.train$voted_obama)
confusionMatrix(df.table)
pred <- prediction(df.train$prob, df.train$vote_2008=='barack obama')
auc <- performance(pred, "auc")
auc <- unlist(slot(auc, "y.values"))
## 1b
df.test$prob <- predict(model_all_fts,newdata = df.test, type = "response")
df.test$pred <- 0
df.test$pred[df.test$prob >= 0.5] <- 1
df.table.test <- table(df.test$pred,df.test$voted_obama)
confusionMatrix(df.table.test)
pred.test <- prediction(df.test$prob, df.test$vote_2008=='barack obama')
auc.test <- performance(pred.test, "auc")
auc.test <- unlist(slot(auc.test, "y.values"))
## 1c
df.train.large <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_complete.tsv")
df.train.large$voted_obama <- ifelse(df.train.large$vote_2008 == 'barack obama',1,0)
model_large <- glm(voted_obama~state+sex+race+age+
education+party+ideology+state_contestedness,
data = df.train.large,
family = "binomial")
summary(model_large)
df.train.large$prob <- predict(model_large,type = "response")
df.train.large$pred <- 0
df.train.large$pred[df.train.large$prob >= 0.5] <- 1
df.table.large <- table(df.train.large$pred,df.train.large$voted_obama)
confusionMatrix(df.table.large)
pred.large <- prediction(df.train.large$prob, df.train.large$vote_2008=='barack obama')
auc.large <- performance(pred.large, "auc")
auc.large <- unlist(slot(auc.large, "y.values"))
df.test.large <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
df.test.large$voted_obama <- ifelse(df.test.large$vote_2008 == 'barack obama',1,0)
df.test.large$prob <- predict(model_large,newdata = df.test.large, type = "response")
df.test.large$pred <- 0
df.test.large$pred[df.test.large$prob >= 0.5] <- 1
df.table.test.large <- table(df.test.large$pred,df.test.large$voted_obama)
confusionMatrix(df.table.test.large)
pred.test.large <- prediction(df.test.large$prob, df.test.large$vote_2008=='barack obama')
auc.test.large <- performance(pred.test.large, "auc")
auc.test.large <- unlist(slot(auc.test.large, "y.values"))
# 2
### a
df <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df$voted_obama <- ifelse(df$vote_2008 == 'barack obama',1,0)
train.rows <- 1:300
df.train <- df[train.rows,]
df.valid <- df[-train.rows,]
df.train <- df.train[,-c(8)]
df.valid <- df.valid[,-c(8)]
### b
df_result <- data.frame(Formula=character(),AUC=numeric())
df_result$Formula <- as.character(df_result$Formula)
df_result$AUC <- as.numeric(df_result$AUC)
df_coef <- colnames(df.train[,1:8])
for(i in 1:length(df_coef)){
df_result[i,1] <- as.character(paste("voted_obama","~",df_coef[i]))
model_forward <- glm(as.formula(df_result[i,1]),
data = df.train,
family = "binomial")
df.valid$prob <- predict(model_forward,newdata = df.valid, type = "response")
pred.valid <- prediction(df.valid$prob, df.valid$voted_obama==1)
auc <- performance(pred.valid, "auc")
df_result[i,2] <- unlist(slot(auc, "y.values"))
}
### c
# result data frame contains training and valid
# intermediate dataframe - training and valid
df_result <- data.frame(Formula=character(),Train_AUC=numeric(),Valid_AUC=numeric())
df_result$Formula <- as.character(df_result$Formula)
df_result$Train_AUC <- as.numeric(df_result$Train_AUC)
df_result$Valid_AUC <- as.numeric(df_result$Valid_AUC)
df_int_result <- data.frame(Formula=character(),Train_AUC=numeric(),Valid_AUC=numeric(),coef = character())
df_int_result$Formula <- as.character(df_int_result$Formula)
df_int_result$Train_AUC <- as.numeric(df_int_result$Train_AUC)
df_int_result$Valid_AUC <- as.numeric(df_int_result$Valid_AUC)
df_int_result$coef <- as.character(df_int_result$coef)
df_coef <- colnames(df.train[,1:8])
for(i in 1:8){
for(j in 1:length(df_coef)){
if(i>1){
df_int_result[j,1] <- as.character(paste(df_result[i-1,1],'+',df_coef[j]))
df_int_result[j,4] <- df_coef[j]
model_forward <- glm(as.formula(df_int_result[j,1]),
data = df.train,
family = "binomial")
df.valid$prob <- predict(model_forward,newdata = df.valid, type = "response")
df.train$prob <- predict(model_forward, type = "response")
pred.train <- prediction(df.train$prob, df.train$voted_obama==1)
pred.valid <- prediction(df.valid$prob, df.valid$voted_obama==1)
auc <- performance(pred.train, "auc")
df_int_result[j,2] <- unlist(slot(auc, "y.values"))
auc <- performance(pred.valid, "auc")
df_int_result[j,3] <- unlist(slot(auc, "y.values"))
}
if(i == 1){
df_int_result[j,1] <- as.character(paste("voted_obama","~",df_coef[j]))
df_int_result[j,4] <- df_coef[j]
model_forward <- glm(as.formula(df_int_result[j,1]),
data = df.train,
family = "binomial")
df.valid$prob <- predict(model_forward,newdata = df.valid, type = "response")
df.train$prob <- predict(model_forward, type = "response")
pred.train <- prediction(df.train$prob, df.train$voted_obama==1)
pred.valid <- prediction(df.valid$prob, df.valid$voted_obama==1)
auc <- performance(pred.train, "auc")
df_int_result[j,2] <- unlist(slot(auc, "y.values"))
auc <- performance(pred.valid, "auc")
df_int_result[j,3] <- unlist(slot(auc, "y.values"))
}
}
maxAUC = max(df_int_result$Valid_AUC)
df_result[i,] = df_int_result[df_int_result$Valid_AUC==maxAUC,1:3]
removeCoef <- df_int_result[df_int_result$Valid_AUC==maxAUC,4]
df_coef <- df_coef[!df_coef %in% removeCoef]
df_int_result <- data.frame(Formula=character(),Train_AUC=numeric(),Valid_AUC=numeric(),coef = character())
df_int_result$Formula <- as.character(df_int_result$Formula)
df_int_result$Train_AUC <- as.numeric(df_int_result$Train_AUC)
df_int_result$Valid_AUC <- as.numeric(df_int_result$Valid_AUC)
df_int_result$coef <- as.character(df_int_result$coef)
}
ggplot()+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,2],color = "Training AUC"))+
geom_smooth(mapping = aes(x = 1:8, y = df_result[,3],color = "Validation AUC"))+
xlab("No. of features")+ylab("AUC")
df.train <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df.test <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
df.train$voted_obama <- ifelse(df.train$vote_2008 == 'barack obama',1,0)
df.test$voted_obama <- ifelse(df.test$vote_2008 == 'barack obama',1,0)
df.train <- df.train[,-c(8)]
df.test <- df.test[,-c(8)]
model_final <- glm(voted_obama ~ party + ideology + race + sex,
data = df.train,family = "binomial")
df.test$prob <- predict(model_final,newdata = df.test,type = "response")
pred.test <- prediction(df.test$prob, df.test$voted_obama==1)
auc_Q2 <- performance(pred.test, "auc")
auc_Q2 <- unlist(slot(auc_Q2, "y.values"))
# 3
df.train <- read.delim("https://5harad.com/mse125/assets/hw7/poll_train_small.tsv")
df.test <- read.delim("https://5harad.com/mse125/assets/hw7/poll_test.tsv")
df.train$voted_obama <- ifelse(df.train$vote_2008 == 'barack obama',1,0)
df.test$voted_obama <- ifelse(df.test$vote_2008 == 'barack obama',1,0)
# Removing the vote_2008 column
df.train <- df.train[,-c(8)]
df.test <- df.test[,-c(8)]
library(glmnet)
x <- model.matrix(voted_obama ~ ., df.train)[,-1]
y <- df.train$voted_obama
lasso.model <- glmnet(x,y,alpha = 1,lambda = 0.01,
family = "binomial")
ridge.model <- glmnet(x,y,alpha = 0,lambda = 0.01,
family = "binomial")
x_val <- model.matrix(voted_obama ~ ., df.test)[,-1]
p.lasso <- predict(lasso.model, newx = x_val, type = "response")
p.ridge <- predict(ridge.model, newx = x_val, type = "response")
pred.lasso <- prediction(p.lasso,df.test$voted_obama)
pred.ridge <- prediction(p.ridge,df.test$voted_obama)
auc.lasso <- performance(pred.lasso,"auc")
auc.lasso <- unlist(slot(auc.lasso, "y.values"))
auc.ridge <- performance(pred.ridge,"auc")
auc.ridge <- unlist(slot(auc.ridge, "y.values"))
coef(lasso.model)
coef(ridge.model)
# 3 b
lambdas <- 10^seq(-3,2,.01)
lasso.model <- glmnet(x,y,alpha = 1,lambda = lambdas,
family = "binomial")
ridge.model <- glmnet(x,y,alpha = 0,lambda = lambdas,
family = "binomial")
plot(lasso.model,xvar = "lambda", label = TRUE )
plot(ridge.model,xvar = "lambda", label = TRUE )
``
plot(ridge.model,xvar = "lambda", label = TRUE )
auc_Q2
auc.test
setwd("~/GitHub/MSE_246_p1")
ls()
# This file will do an initial data cleaning/addition of the SBA loan dataset
# Authors: Daniel, Brent, Peng and Yash
# File Description:
# Inputs:
# Outputs:
library(dplyr)
library(GGally)
library(survival)
library(ROCR)
set.seed(1)
df <- read.csv("SBA_loan_data_new.csv")
# Macroeconomic data sets
unemployment_data <- read.csv("emp-unemployment.csv")
# FED Interest Rate data per year
# Source: https://fred.stlouisfed.org/series/DFF/downloaddata
interest_rates_data <- read.csv("FED_IR.csv")
# Total Economic Cost due to Tornados per year per state
# Source: http://www.spc.noaa.gov/wcm/test.html (manipulated using R and excel)
Tornado_damage_economic <- read.csv("Tornado FL.csv")
# Small Business Lending data stats per state for 2011
# Source:
# 1. https://www.sba.gov/advocacy/firm-size-data
# 2. https://www.sba.gov/content/small-business-lending-united-states-2010-2011
Small_business_lending_data <- read.csv("Small_Business_lending_stats.csv")
SBLR <- c(rep(0,length(df$BorrState)))
for (i in 1:length(df$BorrState)) {
SBLR[i]=Small_business_lending_data[match(df$BorrState[i],Small_business_lending_data$State),5]
}
#Add small business loan ratio (total small business loans issued/total small businesses per state )
df=cbind(df,SBLR)
# Average HPI Index by State for 1990-2016
hpi_state <- read.csv("hpi_state.csv", header=TRUE, stringsAsFactors=F)
hpi_state$ProjectState = as.factor(hpi_state$ProjectState)
df <- left_join(df, hpi_state, by=c("ProjectState", "ApprovalFiscalYear"))
df$mn_hpi = as.numeric(df$mn_hpi)
# Filtering out Loans which are canceled or exempt
df <- filter(df, LoanStatus != "CANCLD")
df <- filter(df, LoanStatus != "EXEMPT")
df <- filter(df, DeliveryMethod != "504REFI")
# Removing the first 3 columns of the data set  as they contain the common program info and a
# unique identifying name for every business
df <- df[,-c(1,2,3)]
# Removing the column BorrZip Code
df <- df[,-c(3)]
# Removing CDC street, city, zip
df <- df[,-c(4,5,6,7)]
# Adding 4 columns - isDefault, NotSameState, ThirdPartyApproved and dayselapsed
df$isDefault <- ifelse(df$LoanStatus=="CHGOFF",1,0)
df$isDefault <- factor(df$isDefault)
df$isDefault <- as.numeric(df$isDefault)
df$NotSameState <- factor(df$NotSameState)
df$ThirdPartyApproved <- factor(df$ThirdPartyApproved)
df <- mutate(df,dayselapsed = as.numeric(difftime(strptime(ChargeOffDate, format = "%m/%d/%Y"),
strptime(ApprovalDate, format = "%m/%d/%Y"))))
df$dayselapsed[is.na(df$dayselapsed)] <- 7300
# Removing the Third Party Lender Name, City, State
df <- df[,-c(4,5,6)]
# Removing subpgmdesc
df <- df[,-c(9)]
# Removing NAICS description
df <- df[,-c(12)]
# Removing Project County and State
df <- df[,-c(12,13)]
df <- mutate(df,Naics2digits = substr(NaicsCode,1,2))
interest_rates=matrix(0,nrow=length(df$ApprovalFiscalYear),ncol=length(1990:2014))
for (i in 1:length(1990:2014)) {
interest_rates[,i]=interest_rates_data[match(1989+i,interest_rates_data$Year),2]
}
for (i in 1:length(df$ApprovalFiscalYear)){
if ((round(df$dayselapsed[i]/365)+1990) < 2014) {
j = 2014-(round(df$dayselapsed[i]/365)+1990)
column_final=length(1990:(round(df$dayselapsed[i]/365)+1990))
for (n in  column_final:25){
interest_rates[i,n]==0}
}
}
# Writing the cleaned dataframe to a csv file
write.csv(df,file = "SBA_cleaned_data.csv")
# This file will do a hazard model-survival analysis on the SBA loan dataset
# Authors: Daniel, Brent, Peng and Yash
# File Description:
# Inputs:
# Outputs:
library(dplyr)
library(GGally)
library(survival)
library(ROCR)
set.seed(1)
df <- read.csv("SBA_cleaned_data.csv")
# Creation of Train, Validation and Test set for Time Series Sampling
df.train.ts <- filter(df,ApprovalFiscalYear <= 2002)
df.valid.ts <- filter(df,ApprovalFiscalYear > 2002 & ApprovalFiscalYear <= 2006)
df.test.ts <- filter(df,ApprovalFiscalYear>2006)
# Creation of Training Set for Random Sampling
train.random.rows <- sample(nrow(df),floor(0.7*nrow(df)))
df.train.random <- df[train.random.rows,]
df.valid.test.random <- df[-train.random.rows,]
valid.random.rows <- sample(nrow(df.valid.test.random),floor(0.2*nrow(df)))
# Creation of Valid and Test set for Random Sampling
df.valid.random <- df.valid.test.random[valid.random.rows,]
df.test.random <- df.valid.test.random[-valid.random.rows,]
####
glm.fit <- glm((isDefault-1) ~ GrossApproval*TermInMonths+
GrossApproval*DeliveryMethod+Naics2digits,data = df.train.ts,family="binomial")
summary(glm.fit)
glm.prob.val <- predict(glm.fit,newdata = df.valid.ts,type = "response")
glm.pred.val <- rep(0,nrow(df.valid.ts))
glm.pred.val[glm.prob.val>0.2] <- 1
glm.pred.val <- as.factor(glm.pred.val)
table(glm.pred.val,(df.valid.ts$isDefault-1))
mean(glm.pred.val==(df.valid.ts$isDefault-1))
# ROC Curve
roc <- performance(prediction(glm.prob.val,df.valid.ts$isDefault-1),measure = "tpr",x.measure = "fpr")
plot(roc)
auc <- performance(prediction(glm.prob.val,df.valid.ts$isDefault-1),measure = "auc")
auc <- auc@y.values[[1]]
auc
# Survival Analysis
mod.coxph <- coxph(Surv(dayselapsed,isDefault)~GrossApproval+Naics2digits+DeliveryMethod
,data=df.train.ts)
mod.coxph
mod.coxph.prob = predict(mod.coxph, type = "risk")
mod.coxph.pred = rep(1, nrow(df.train.ts))
mod.coxph.pred[mod.coxph.prob>=2.4] = 2
table(mod.coxph.pred, df.train.ts$isDefault)
mean(mod.coxph.pred==df.train.ts$isDefault)
plot(survfit(mod.coxph),ylim = c(0.9,1))
hist(mod.coxph.prob)
plot(survfit(mod.coxph,newdata = df.test.ts[1:10,]),ylim=c(0.6,1))
View(df)
lossRatio <- df$GrossChargeOffAmount/df$GrossApproval
hist(lossRatio)
df_default <- df[df$GrossChargeOffAmount>0,]
lossRatio <- df_default$GrossChargeOffAmount/df_default$GrossApproval
hist(lossRatio)
library(ggplot2)
ggplot(data = lossRatio) + geom_histogram(mapping = aes())
?geom_histogram
ggplot(data = lossRatio) + geom_histogram(mapping = aes(binwidth = 0.05))
ggplot(data = factor(lossRatio)) + geom_histogram(mapping = aes(binwidth = 0.05))
ggplot(data = factor(lossRatio)) + geom_histogram(mapping = aes(binwidth = 0.05))
ggplot() + geom_histogram(data = lossRatio,mapping = aes(binwidth = 0.05))
?hist
hist(x = lossRatio)
density(lossRatio)
plot(density(lossRatio))
plot(density(lossRatio),title("Loss given default plot"))
plot(density(lossRatio),title("Loss given default plot"))
plot(density(lossRatio),title(main = "Loss given default plot"))
plot(density(lossRatio),title(main = "Loss given default plot"))
plot(density(lossRatio),title(main = "Loss given default plot"))
plot(density(lossRatio))+title("Loss Given Default")
plot(density(lossRatio),title("Loss Given Default"))
plot(density(lossRatio),title("Loss Given Default"))
plot(density(lossRatio),title = "Loss Given Default")
?title
plot(density(lossRatio))
title("Loss Given Default")
plot(density(lossRatio),main = "")
title("Loss Given Default")
plot(density(lossRatio),main = "")+title("Loss Given Default")
glm.pred.val
glm.pred.val*df.valid.ts$GrossApproval
sum(glm.pred.val*df.valid.ts$GrossApproval)
plot(density(lossRatio),main = "Loss Given Default")
df_default <- df[df$GrossChargeOffAmount>0,]
lossRatio <- df_default$GrossChargeOffAmount/df_default$GrossApproval
plot(density(lossRatio),main = "Loss Given Default")
df_default <- df[df$GrossChargeOffAmount>0,]
lossRatio <- df_default$GrossChargeOffAmount/df_default$GrossApproval
plot(density(lossRatio),main = "Loss Given Default")
?density
defaultEvent <- glm.pred.val
grossApprovedAmount <- df.valid.ts$GrossApproval
defaultEvent*grossApprovedAmount
grossApprovedAmount
defaultEvent
nrow(defaultEvent)
class(defaultEvent)
as.matrix(defaultEvent)*as.matrix(grossApprovedAmount)
as.matrix(as.numeric(defaultEvent))*as.matrix(grossApprovedAmount)
as.numeric(defaultEvent)
as.numeric(defaultEvent)-1
as.matrix(as.numeric(defaultEvent)-1)*as.matrix(grossApprovedAmount)
as.data.frame(as.numeric(defaultEvent)-1)*as.data.frame(grossApprovedAmount)
plot(glm.pred.val)
plot(defaultEvent)
plot(as.numeric(defaultEvent))
lgd_sampled <- sample(lossRatio,nrow(df.valid.ts),replace = TRUE)
class(lgd_sampled)
lgd_sampled*defaultEvent*grossApprovedAmount
VaRTable <- cbind(defaultEvent[defaultEvent>0],grossApprovedAmount[grossApprovedAmount>0])
defaultEvent <- as.data.frame(as.numeric(glm.pred.val)-1)
grossApprovedAmount <- as.data.frame(df.valid.ts$GrossApproval)
View(defaultEvent)
colnames(defaultEvent) <- c("1")
colnames(grossApprovedAmount) <- c("1")
VaRTable <- cbind(defaultEvent[defaultEvent$`1`>0],grossApprovedAmount[grossApprovedAmount$`1`>0])
VaRTable <- cbind(defaultEvent[defaultEvent$`1`>0,],grossApprovedAmount[grossApprovedAmount$`1`>0,])
VaRTable <- cbind(defaultEvent,grossApprovedAmount)
defaultEvent <- as.data.frame(as.numeric(glm.pred.val)-1)
grossApprovedAmount <- as.data.frame(df.valid.ts$GrossApproval)
VaRTable <- cbind(defaultEvent,grossApprovedAmount)
View(VaRTable)
colnames(VaRTable) <- c("defaultEvent","grossApprovedAmount")
VaRTable <- VaRTable[VaRTable$defaultEvent>0,]
loss <- rep(0,1000)
set.seed(1)
defaultEvent <- as.data.frame(as.numeric(glm.pred.val)-1)
grossApprovedAmount <- as.data.frame(df.valid.ts$GrossApproval)
VaRTable <- cbind(defaultEvent,grossApprovedAmount)
colnames(VaRTable) <- c("defaultEvent","grossApprovedAmount")
VaRTable <- VaRTable[VaRTable$defaultEvent>0,]
# Get Loss given default distribution
df_default <- df[df$GrossChargeOffAmount>0,]
lossRatio <- df_default$GrossChargeOffAmount/df_default$GrossApproval
plot(density(lossRatio),main = "Loss Given Default")
## For multiple iterations (Monte Carlo sim)
loss <- rep(0,1000)
for(i in 1:1000){
VaRTable$lgd <- sample(lossRatio,nrow(VaRTable),replace = TRUE)
VaRTable$loss <- VaRTable$lgd*VaRTable$grossApprovedAmount
loss[i] <- sum(VaRTable$loss)
}
# Using the distribution for the Loss Given Default, find the expected loss for each loan
plot(density(loss))
hist(loss)
quantile(loss,c(.95,.99))
sum(grossApprovedAmount)
sum(grossApprovedAmount$`df.valid.ts$GrossApproval`)
sum(df.valid.ts$GrossApproval)
sum(as.numeric(df.valid.ts$GrossApproval))
nrow(VaRTable)
sum(VaRTable$grossApprovedAmount)
